{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import unicodedata\n",
    "\n",
    "file_name=\"./csv/0_500_union_salida_clasificada.csv\"\n",
    "stop_file=\"custom_stopwords.txt\"    # Nombre del archivo de stopwords.\n",
    "\n",
    "# Regex para emoticones en texto.\n",
    "emoticons_str = r\"\"\"\n",
    "(?:\n",
    "    [:=;]               # Ojos\n",
    "    [oO\\-]?             # Nariz (optional)\n",
    "    [D\\)\\]\\(\\]/\\\\OpP]   # Bocas\n",
    ")\"\"\"\n",
    "\n",
    "# Regex para tokenizar correctamente.\n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'(?:[\\w_]+)',                                        # Otras palabras\n",
    "    r'(?:\\S)'                                             # Cualquier otra cosa\n",
    "]\n",
    "\n",
    "# Se arman objetos para regular expresions.\n",
    "tokens_re   = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "# Se carga archivos de STOPWORDS\n",
    "with open(stop_file, newline='') as file:\n",
    "    stopwords = file.read().splitlines()\n",
    "\n",
    "    \n",
    "# Se abre archivo con tweets y se lo recorre    \n",
    "with open(file_name, newline='') as csvfile:\n",
    "\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\\\"')\n",
    "    header = next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "\n",
    "        tweet = row[1].lower()                    # Se normaliza texto, todo a minusculas.\n",
    "        tweet = re.sub(r'@[a-z0-9_]+', '', tweet) # Se quitan menciones. @xxxxxxxx\n",
    "        tweet = re.sub(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', '', tweet)\n",
    "        #tweet = re.sub(r'\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+', '', tweet)\n",
    "        #tweet = re.sub(r'(#)', '', tweet)\n",
    "        tweet = tweet.translate(str.maketrans('','', '.~Â¡!-_â€”#$%Â¿?:+-/Â°);(/\",*â€œâ€â€˜â€™'))\n",
    "        \n",
    "        # Manejo de emoticones.\n",
    "        emoticones = [\n",
    "                      ['ğŸ˜†',' risa'],['ğŸ˜‚','risa'],['ğŸ˜±',' asombro'],['ğŸ¥³',' felicidad'],['ğŸ’™',' amor'],['ğŸ˜',' amor'],\n",
    "                      ['ğŸ˜€',' sonreir'],['ğŸ‘',' ok'],['ğŸ¤”',' ok'],['ğŸŠ',' piÃ±ata'],['ğŸ™',' ojala'],['ğŸ’ªğŸ»',' fuerza'],\n",
    "                      ['ğŸ˜¡',' enojo'],['ğŸ˜›',' broma'],['ğŸ˜®',' asombro'],['ğŸ¤®',' desagradable'],['ğŸ‘ğŸ»',' aplauso'],\n",
    "                      ['ğŸ˜',' canchero'],['ğŸ˜©',' decepcion'],['ğŸ˜³',' verguenza'],['ğŸ˜Š',' contento'],['ğŸ˜¥',' triste'],\n",
    "                      ['ğŸ˜¤',' furioso'],['ğŸ–•',' enojo'],['ğŸ‘',' aplauso'],['ğŸ’ª',' fuerza']\n",
    "                     ]\n",
    "        for emoji in emoticones:\n",
    "            tweet = tweet.replace(emoji[0], emoji[1])\n",
    "\n",
    "        # Manejo de acentos.\n",
    "        dict_acentos = [['Ã¡','a'],['Ã©','e'],['Ã­','i'],['Ã³','o'],['Ãº','u']]\n",
    "        for acento in dict_acentos:\n",
    "            tweet = tweet.replace(acento[0], acento[1])\n",
    "            \n",
    "        # Remueve letras repetidas y deja una sola.\n",
    "        for letra in ['a','e','i','o','u','s','c']:\n",
    "            pattern = letra + '{2,}'\n",
    "            tweet = re.sub(pattern, letra, tweet)\n",
    "        \n",
    "        tweet = tweet.translate(str.maketrans('','', 'ğŸ¥ğŸ§ğŸ³ğŸ–ğŸ›«ğŸ˜‘âœˆğŸ‡¦ğŸ‡·ğŸ‡µğŸ‡¾ğŸ‘‡ğŸ™ƒâ–¶ğŸ’»â–ºâ†’â¬‡ï¸ğŸ˜’ğŸ™„ğŸ”«ğŸ”ğŸ”¥ğŸ’€ğŸš«ğŸ˜ğŸ¤¦â€â™‚â¤â¤â¤ğŸ˜ğŸ‘Šï£¿ğŸ¤ğŸ»'))\n",
    "        tweet = re.sub(r'\\d+', '', tweet)         # Se quitan numeros.\n",
    "        tweet = tweet.strip()\n",
    "    \n",
    "        # Tokenizado\n",
    "        tokens = tokens_re.findall(tweet)\n",
    "\n",
    "        # Remocion de stopwords\n",
    "        tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "        print(tokens)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
